ğŸ§­ Multi-Rate Â· Multi-Type Unsupervised Sensor Anomaly Detection
Full Research & Engineering Roadmap (Markdown)
#ï¸âƒ£ Overview

ë³¸ í”„ë¡œì íŠ¸ì˜ ëª©í‘œëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë³µí•© ì¡°ê±´ì—ì„œ scalableÂ·unsupervised anomaly detection pipeline êµ¬ì¶•:

Multi-Rate: {2000Hz, 200Hz, 50Hz, Non-Periodic}

Multi-Type: {1word(16bit), 2word(32bit, MSB/LSB), complex(bitwise multi-field)}

Dataset dimension ë³€í™”ì—ë„ ì•ˆì •ì ìœ¼ë¡œ ì‘ë™

ëŒ€ê·œëª¨ ë°ì´í„° â†’ Fully supervised ë°©ì‹ ë¶ˆê°€

Temporal ë¹„ì •ìƒ(Anomaly) íƒì§€ í•„ìš”

ğŸ— ì „ì²´ Architecture (Stage 1 â†’ Stage 3)
```pgsql
Raw Multi-Rate Sensors
        â”‚
        â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Stage 1. Pre-Classifier (Data Type ID)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚ type label
        â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Stage 2. Representation Learning
   2.1 Type-Specific Network
   2.2 Rate Header Network
   2.3 Body Fusion Network (GNN/LSTM)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚ unified representation
        â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
 Stage 3. Fine-Tune (Human-in-the-loop)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        â”‚
        â–¼
   Anomaly per timestep


```

ğŸ¯ Stage 1 â€” Pre-Classifier (Data Type Identification)
ğŸ“Œ ëª©í‘œ

Multi-Type(1word/2word/complex)ì„ ìë™ ì‹ë³„í•˜ì—¬
ê° rateë³„ type ë¼ìš°íŒ… ìë™í™”

ì‹¤ì œ ë°ì´í„°ëŠ” type labelì´ ë¶€ì¡±í•˜ë¯€ë¡œ
random synthetic generation ê¸°ë°˜ Self-Supervised classifier í•™ìŠµ

ğŸ“Œ í•´ì•¼ í•  ì¼ (To-Do)
1.1 Synthetic Multi-Type Data Generator ê°œì„ 

âœ“ 1word, 2word(MSB/LSB), complex-bit êµ¬ì¡° ì •í™•íˆ ìƒì„±

âœ“ Real distribution matching (amplitude, correlation, burst event, overflow ë“±)

âœ“ ê° rateë³„ ë‹¤ë¥¸ noise profile êµ¬ì¶•

âœ“ Non-periodic ì´ë²¤íŠ¸ë„ í¬í•¨

1.2 Pre-Classifier Architecture ì„¤ê³„

ì…ë ¥ ê¸¸ì´ ë³€í™” ëŒ€ì‘ì„ ìœ„í•´:

ì˜µì…˜ A) Adaptive Pooling ê¸°ë°˜ CNN

1Ã—T â†’ adaptive_avg_pool â†’ 1Ã—fixed

ì°¨ì›ì´ ë‹¬ë¼ë„ ë™ì¼í•œ classifier ì‚¬ìš© ê°€ëŠ¥

Temporal structure ì¼ë¶€ ë³´ì¡´

ì˜µì…˜ B) GNN (Graph-of-Time)

timestepì„ nodeë¡œ ë³´ê³  multi-rate merging ê°€ëŠ¥

irregular samplingë„ ì²˜ë¦¬ ê°€ëŠ¥

ì˜µì…˜ C) LSTM/Transformer + packed sequence

variable length batch ì²˜ë¦¬ ê°€ëŠ¥

í•˜ì§€ë§Œ multi-rate alignment í•„ìš”ì„± â†‘

=> ì¶”ì²œ: ì˜µì…˜ A (Adaptive CNN) + ì˜µì…˜ C (Packed LSTM)

1.3 Loss êµ¬ì„±

Cross-entropy(type classification)

2wordì— ëŒ€í•´ MSB/LSB alignment loss ì¶”ê°€

L_msb_lsb = BCE(pred_MSB, GT_MSB) + BCE(pred_LSB, GT_LSB)

1.4 ì¶œë ¥

type_id âˆˆ {1word, 2word, complex}

optional: bit-mask / MSB-LSB pair confidence

ğŸ¯ Stage 2 â€” Representation Learning Core

Stage 1ì—ì„œ typeì´ ê²°ì •ë˜ë©´ sensorëŠ” ì•„ë˜ pathë¡œ ë“¤ì–´ê°.

2.1 Type-Specific Network
ğŸ“Œ ëª©í‘œ

Typeë³„ë¡œ ì ì ˆí•œ encoder ì‚¬ìš©

Hidden sizeëŠ” ë™ì¼í•˜ì—¬ downstream fusionì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ê³„

Type	ì…ë ¥ ì˜ˆì‹œ	ê¶Œì¥ Network
1word	ì •ìˆ˜ ë˜ëŠ” float ê°’	CNN / LSTM encoder
2word	MSB/LSB	bit-GNN ë˜ëŠ” MLP pair encoder
complex bits	multi-field / bitmask	Bit-GNN, Set Transformer
ğŸ“Œ í•´ì•¼ í•  ì¼ (To-Do)

âœ“ ê° type encoderë¥¼ ëª¨ë“ˆí™”

âœ“ embedding dimension í†µì¼ (ex. 128d)

âœ“ Contrastive learning ë„ì…

time-shift positive / other rate negative

overflowÂ·burst event ë³„ë¡œ event-level contrastive í•™ìŠµ

2.2 Rate Header Network
ğŸ“Œ ëª©í‘œ

ê° rate encoder ì¶œë ¥ â†’ ì„œë¡œ ë‹¤ë¥¸ samplingì—ë„ ê³µí†µ ê³µê°„ìœ¼ë¡œ projection

ë¹„ìœ : ì„œë¡œ ë‹¤ë¥¸ ê¸¸ì´ì˜ ì˜ìƒì„ ì°ì—ˆì§€ë§Œ ë™ì¼í•œ descriptorë¡œ ë§Œë“œëŠ” ë‹¨ê³„.

ğŸ“Œ í•´ì•¼ í•  ì¼ (To-Do)

âœ“ {2kHz, 200Hz, 50Hz, Non-periodic} encoder ê°ê° êµ¬ì„±

âœ“ Temporal pooling ì „ëµ ì„ íƒ

Adaptive pooling

Learnable pooling(weighted pooling)

Temporal attention pooling

âœ“ Output shape

H_rate = [B, 128]   # ëª¨ë“  rate ë™ì¼ ì°¨ì›

2.3 Body Fusion Network (Multi-Rate Integration)
ğŸ“Œ ëª©í‘œ

ê° rateì˜ representationì„ í†µí•©í•´
â€œì‹œì ë³„ ì „ì²´ sensor system representationâ€ ìƒì„±.

ğŸ“Œ í›„ë³´ ë°©ì‹
A. GNN with Rate Graph

Node = sensor rate

Edge = causal/temporal correlation

Multi-rate irregular ë°ì´í„°ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ fusion

B. Hierarchical Temporal Fusion Transformer

low rate â†’ upsampleí•˜ì—¬ high rateì— alignment

temporal attentionìœ¼ë¡œ multi-resolution ì²˜ë¦¬

C. Mixture-of-Experts (Soft/Hard gating)

high rate â†’ detail

low rate â†’ trend

gatingìœ¼ë¡œ dynamic fusion

ğŸ“Œ í•´ì•¼ í•  ì¼ (To-Do)

âœ“ Rateê°„ attention matrix í•™ìŠµ

âœ“ Fusion vector ì¶œë ¥

âœ“ Stage 3ì™€ ì—°ê²°

2.4 Output (Unsupervised / Semi-Supervised)
ğŸ“Œ ëª©í‘œ

ê° ì‹œê°„ í”„ë ˆì„ë§ˆë‹¤ ì •ìƒ/ë¹„ì •ìƒ íŒë‹¨

ğŸ¯ Stage 3 â€” Fine-Tuning (Human-in-the-Loop)
ğŸ“Œ ëª©ì 

Real-world anomalyì— ëŒ€í•´ ì‚¬ëŒì´ label ìˆ˜ì •í•˜ì—¬
ëª¨ë¸ì˜ false positive/negative ë°¸ëŸ°ìŠ¤ë¥¼ ê°œì„ 

ğŸ“Œ í•´ì•¼ í•  ì¼ (To-Do)
3.1 Human feedback loop

domain expertê°€ time frame ë³„ anomaly ê²€ì¦

ëª¨ë¸ output vs human ìˆ˜ì •

3.2 Loss ë°˜ì˜

Semi-supervised loss:

L = L_consistency + L_reconstruction + L_human_label

3.3 Active learning loop

ë¶ˆí™•ì‹¤ë„ê°€ ë†’ì€ êµ¬ê°„ë§Œ samplingí•˜ì—¬ labeling íš¨ìœ¨â†‘

ğŸ“¦ Module êµ¬ì„± (ê°œë°œí•  íŒŒíŠ¸)
âœ¨ Module 1 â€” Multi-Rate Multi-Type Generator

random + real-statistics ê¸°ë°˜

1word / 2word / complex bit êµ¬ì¡° ìƒì„±

âœ¨ Module 2 â€” Pre-Classifier

type classifier

MSB/LSB classifier

bitmask approximate detection

âœ¨ Module 3 â€” Type-Specific Encoders
âœ¨ Module 4 â€” Rate Header Networks
âœ¨ Module 5 â€” Body Fusion Network

GNN ë˜ëŠ” Transformer ê¸°ë°˜

âœ¨ Module 6 â€” Anomaly Inference Head

reconstruction error ê¸°ë°˜

contrastive distance ê¸°ë°˜

event-level detection

âœ¨ Module 7 â€” Fine-Tune + Feedback Trainer
ğŸ¯ ìµœì¢… ê²°ê³¼ë¬¼

Pre-classifierë¡œ rateë³„ type ìë™ ì‹ë³„

Type-specific encoderë¡œ effective compression

Rate header â†’ Body fusionìœ¼ë¡œ system-level representation

Human-in-the-loopë¡œ fine tune

Dataset dimension ë³€í™”ì—ë„ ì‘ë™í•˜ëŠ” scalable architecture ì™„ì„±
