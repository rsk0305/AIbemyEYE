# AIbemyEYE


Soft â†” Hard gating ì „í™˜ ì „ëµ í¬í•¨ MoE multi-modal pipelineì„ Mermaid flowë¡œ ì‹œê°í™”

**heterogeneous ì„¼ì„œ ì…ë ¥, gating network, expert encoders, soft/hard gating ì„ íƒ, fusion, shared embedding, downstream task, EVT thresholdê¹Œì§€ í¬í•¨ë©ë‹ˆë‹¤.**

```mermaid
flowchart TD
    %% ================= Inputs =================
    subgraph Inputs["ğŸŸ¦ Multi-Modal Sensor Inputs"]
        X1["X1: Binary / 1bit"]
        X2["X2: 2-word / 16bit"]
        X3["X3: Float / Int"]
        X4["X4: Multi-bit (3~15 bits)"]
    end

    %% ================= Initial Embedding =================
    subgraph InitEmbed["ğŸŸ¨ Initial Embedding / Preprocessing"]
        PRE1["Binary â†’ bitwise linear â†’ hidden_dim"]
        PRE2["2-word â†’ optional bit embedding â†’ linear â†’ hidden_dim"]
        PRE3["Float/Int â†’ linear â†’ hidden_dim"]
        PRE4["Multi-bit â†’ linear â†’ hidden_dim"]
    end

    X1 --> PRE1
    X2 --> PRE2
    X3 --> PRE3
    X4 --> PRE4

    %% ================= Gating Network =================
    subgraph Gating["ğŸŸ© Gating Network"]
        GATE["MLP â†’ softmax â†’ gating_prob (soft)"]
        SOFT["Soft Gating â†’ weighted sum of all Expert outputs"]
        HARD["Hard Gating â†’ argmax / top-k selection"]
        SWITCH["Soft â†” Hard Switch (training phase dependent)"]
    end

    PRE1 --> GATE
    PRE2 --> GATE
    PRE3 --> GATE
    PRE4 --> GATE
    GATE --> SWITCH
    SWITCH --> SOFT
    SWITCH --> HARD

    %% ================= Expert Encoders =================
    subgraph Experts["ğŸŸ§ Expert Encoders (MoE)"]
        E1["Expert 1: Binary-focused"]
        E2["Expert 2: Float/Int-focused"]
        E3["Expert 3: Multi-bit / High-cardinality"]
    end

    SOFT --> E1
    SOFT --> E2
    SOFT --> E3

    HARD --> E1
    HARD --> E2
    HARD --> E3

    %% ================= Fusion Layer =================
    subgraph Fusion["ğŸŸ¨ Fusion Layer / Shared Embedding"]
        CONCAT["Concat / Attention / Weighted sum"]
        Z_shared["Shared embedding z_t"]
    end

    E1 --> CONCAT
    E2 --> CONCAT
    E3 --> CONCAT
    CONCAT --> Z_shared

    %% ================= Downstream =================
    subgraph Downstream["ğŸŸª Downstream Tasks"]
        PRETRAIN["Self-Supervised: CPC / Contrastive / Recon Loss"]
        FINETUNE["MIL / Weak Label Fine-tune"]
        HUMAN["Human Feedback / Pseudo-label update"]
        CONTINUAL["Continual Fine-tune / Drift adaptation"]
        EVT["EVT / Percentile Threshold"]
        LABEL["Normal / Abnormal Label"]
    end

    Z_shared --> PRETRAIN --> FINETUNE --> HUMAN --> CONTINUAL --> EVT --> LABEL

    %% ================= Legend / Notes =================
    classDef inputs fill:#d0ebff,stroke:#000,stroke-width:1px;
    classDef preprocessing fill:#fff3bf,stroke:#000,stroke-width:1px;
    classDef gating fill:#c3f0ca,stroke:#000,stroke-width:1px;
    classDef experts fill:#ffd6d6,stroke:#000,stroke-width:1px;
    classDef fusion fill:#fff3bf,stroke:#000,stroke-width:1px;
    classDef downstream fill:#e0c3ff,stroke:#000,stroke-width:1px;

    class Inputs inputs;
    class InitEmbed preprocessing;
    class Gating gating;
    class Experts experts;
    class Fusion fusion;
    class Downstream downstream;

```


ì‚¬ìš© ì„¤ëª… (ê°„ë‹¨)

generate_multimodal_data_advanced(...) í˜¸ì¶œë¡œ ì„¼ì„œ ë¦¬ìŠ¤íŠ¸ì™€ (N x target_T) ì •ë ¬ëœ í–‰ë ¬ì„ ì–»ìŠµë‹ˆë‹¤.

MoEMultiSensorDatasetëŠ” PyTorch í•™ìŠµ ë£¨í‹´ì— ë°”ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆëŠ” í˜•íƒœë¡œ ê° ì„¼ì„œì˜ ì›ì‹œ(raw)ì™€ ì •ë ¬(aligned) ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

anomaly insertëŠ” anomaly_cfg íŒŒë¼ë¯¸í„°ë¡œ ì œì–´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

use_multirate=Trueì´ë©´ ì„¼ì„œë³„ë¡œ ëœë¤í•˜ê²Œ 50/200/2000Hzë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ì‹œ ë°ì´í„°ë¥¼ ë§Œë“¤ê³ , ë§ˆì§€ë§‰ì— ëª¨ë‘ resampleë¡œ target_T ê¸¸ì´ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.
