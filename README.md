# AIbemyEYE


Soft â†” Hard gating ì „í™˜ ì „ëžµ í¬í•¨ MoE multi-modal pipelineì„ Mermaid flowë¡œ ì‹œê°í™”

**heterogeneous ì„¼ì„œ ìž…ë ¥, gating network, expert encoders, soft/hard gating ì„ íƒ, fusion, shared embedding, downstream task, EVT thresholdê¹Œì§€ í¬í•¨ë©ë‹ˆë‹¤.**

```mermaid
flowchart TD
    %% ================= Inputs =================
    subgraph Inputs["ðŸŸ¦ Multi-Modal Sensor Inputs"]
        X1["X1: Binary / 1bit"]
        X2["X2: 2-word / 16bit"]
        X3["X3: Float / Int"]
        X4["X4: Multi-bit (3~15 bits)"]
    end

    %% ================= Initial Embedding =================
    subgraph InitEmbed["ðŸŸ¨ Initial Embedding / Preprocessing"]
        PRE1["Binary â†’ bitwise linear â†’ hidden_dim"]
        PRE2["2-word â†’ optional bit embedding â†’ linear â†’ hidden_dim"]
        PRE3["Float/Int â†’ linear â†’ hidden_dim"]
        PRE4["Multi-bit â†’ linear â†’ hidden_dim"]
    end

    X1 --> PRE1
    X2 --> PRE2
    X3 --> PRE3
    X4 --> PRE4

    %% ================= Gating Network =================
    subgraph Gating["ðŸŸ© Gating Network"]
        GATE["MLP â†’ softmax â†’ gating_prob (soft)"]
        SOFT["Soft Gating â†’ weighted sum of all Expert outputs"]
        HARD["Hard Gating â†’ argmax / top-k selection"]
        SWITCH["Soft â†” Hard Switch (training phase dependent)"]
    end

    PRE1 --> GATE
    PRE2 --> GATE
    PRE3 --> GATE
    PRE4 --> GATE
    GATE --> SWITCH
    SWITCH --> SOFT
    SWITCH --> HARD

    %% ================= Expert Encoders =================
    subgraph Experts["ðŸŸ§ Expert Encoders (MoE)"]
        E1["Expert 1: Binary-focused"]
        E2["Expert 2: Float/Int-focused"]
        E3["Expert 3: Multi-bit / High-cardinality"]
    end

    SOFT --> E1
    SOFT --> E2
    SOFT --> E3

    HARD --> E1
    HARD --> E2
    HARD --> E3

    %% ================= Fusion Layer =================
    subgraph Fusion["ðŸŸ¨ Fusion Layer / Shared Embedding"]
        CONCAT["Concat / Attention / Weighted sum"]
        Z_shared["Shared embedding z_t"]
    end

    E1 --> CONCAT
    E2 --> CONCAT
    E3 --> CONCAT
    CONCAT --> Z_shared

    %% ================= Downstream =================
    subgraph Downstream["ðŸŸª Downstream Tasks"]
        PRETRAIN["Self-Supervised: CPC / Contrastive / Recon Loss"]
        FINETUNE["MIL / Weak Label Fine-tune"]
        HUMAN["Human Feedback / Pseudo-label update"]
        CONTINUAL["Continual Fine-tune / Drift adaptation"]
        EVT["EVT / Percentile Threshold"]
        LABEL["Normal / Abnormal Label"]
    end

    Z_shared --> PRETRAIN --> FINETUNE --> HUMAN --> CONTINUAL --> EVT --> LABEL

    %% ================= Legend / Notes =================
    classDef inputs fill:#d0ebff,stroke:#000,stroke-width:1px;
    classDef preprocessing fill:#fff3bf,stroke:#000,stroke-width:1px;
    classDef gating fill:#c3f0ca,stroke:#000,stroke-width:1px;
    classDef experts fill:#ffd6d6,stroke:#000,stroke-width:1px;
    classDef fusion fill:#fff3bf,stroke:#000,stroke-width:1px;
    classDef downstream fill:#e0c3ff,stroke:#000,stroke-width:1px;

    class Inputs inputs;
    class InitEmbed preprocessing;
    class Gating gating;
    class Experts experts;
    class Fusion fusion;
    class Downstream downstream;

```


ì‚¬ìš© ì„¤ëª… (ê°„ë‹¨)

generate_multimodal_data_advanced(...) í˜¸ì¶œë¡œ ì„¼ì„œ ë¦¬ìŠ¤íŠ¸ì™€ (N x target_T) ì •ë ¬ëœ í–‰ë ¬ì„ ì–»ìŠµë‹ˆë‹¤.

MoEMultiSensorDatasetëŠ” PyTorch í•™ìŠµ ë£¨í‹´ì— ë°”ë¡œ ì‚¬ìš©ë  ìˆ˜ ìžˆëŠ” í˜•íƒœë¡œ ê° ì„¼ì„œì˜ ì›ì‹œ(raw)ì™€ ì •ë ¬(aligned) ë°ì´í„°ë¥¼ ì œê³µí•©ë‹ˆë‹¤.

anomaly insertëŠ” anomaly_cfg íŒŒë¼ë¯¸í„°ë¡œ ì œì–´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

use_multirate=Trueì´ë©´ ì„¼ì„œë³„ë¡œ ëžœë¤í•˜ê²Œ 50/200/2000Hzë¥¼ ì‚¬ìš©í•˜ì—¬ ì›ì‹œ ë°ì´í„°ë¥¼ ë§Œë“¤ê³ , ë§ˆì§€ë§‰ì— ëª¨ë‘ resampleë¡œ target_T ê¸¸ì´ë¡œ ì •ë ¬í•©ë‹ˆë‹¤.




**"main_pre_classifier.py"** êµ¬ì¡°

```mermaid
flowchart TB
    subgraph INPUT
        S[scene: list of sensors] --> RAW[raw np.array/tensor/list, raw_rate, type, meta]
    end

    subgraph ENCODERS
        RAW --> ENC[RateEncoderTemporal<br>outputs: vec + temporal features]
    end

    subgraph GRAPH
        ENC --> X[X: N x emb]
        X --> G1[SimpleGraphLayer g1]
        G1 --> H1[H1: N x emb]
        H1 --> G2[SimpleGraphLayer g2]
        G2 --> H2[H2: N x emb]
    end

    subgraph HEADS
        H2 --> NODE[node_head: N x 3]
        H2 --> BIT[bitmask_head: N x 16]
        H2 --> PAIR[pair_feat: N x N x 2*emb]
        PAIR --> EDGE[edge_head: N x N]
        PAIR --> ORDER[order_head: N x N x 2]
        ENC --> TEMP[temps: list of L x emb]
        TEMP --> OVERFLOW[overflow temporal conv per-pair<br>conv1->ReLU->conv2->ReLU->conv_out]
    end

    subgraph OUTPUT
        NODE --> OUT[node_logits: N x 3]
        EDGE --> OUT2[edge_logits: N x N]
        ORDER --> OUT3[order_logits: N x N x 2]
        BIT --> OUT4[bitmask_logits: N x 16]
        OVERFLOW --> OUT5[overflow_logits: N x N x L]
        G2 --> ATT[attention: N x N]
    end

